# Bot Mimari DetaylarÄ±

## ğŸ¯ TasarÄ±m Prensipleri

### 1. ModÃ¼ler YapÄ±
- Her kaynak iÃ§in ayrÄ± scraper class'Ä±
- BaseScraper abstract class ile ortak mantÄ±k
- Kolay geniÅŸletilebilir (yeni kaynak eklemek kolay)

### 2. Hata ToleransÄ±
- Bir kaynak hata verse bile diÄŸerleri Ã§alÄ±ÅŸmaya devam eder
- Retry mekanizmasÄ± ile geÃ§ici hatalar yÃ¶netilir
- KalÄ±cÄ± hatalar log'lanÄ±r ve manuel mÃ¼dahale bekler

### 3. Performans
- Paralel scraping (2 kaynak aynÄ± anda)
- Rate limiting ile kaynaklarÄ± koruma
- Browser instance'larÄ± optimize kullanÄ±m

## ğŸ“ Class DiyagramÄ±

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   BaseScraper       â”‚ (Abstract)
â”‚                     â”‚
â”‚ + scrape()          â”‚
â”‚ + parse()            â”‚
â”‚ + normalize()       â”‚
â”‚ - _waitForPage()    â”‚
â”‚ - _extractData()    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â”‚ extends
           â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚             â”‚              â”‚
â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
â”‚Akbank  â”‚  â”‚Turkcell  â”‚  â”‚...        â”‚
â”‚Scraper â”‚  â”‚Scraper   â”‚  â”‚           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ScraperManager     â”‚
â”‚                     â”‚
â”‚ + runAll()          â”‚
â”‚ + runOne()          â”‚
â”‚ - _rateLimit()      â”‚
â”‚ - _handleError()    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Normalizer         â”‚
â”‚                     â”‚
â”‚ + normalize()       â”‚
â”‚ + detectDuplicate() â”‚
â”‚ - _generateHash()   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  APIClient          â”‚
â”‚                     â”‚
â”‚ + postCampaign()    â”‚
â”‚ + getSources()      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”„ Data Flow

### Senaryo: Akbank KampanyalarÄ±nÄ± Ã‡ekme

```
1. Scheduler
   â””â”€> ScraperManager.runOne('akbank')

2. ScraperManager
   â”œâ”€> Rate Limiter kontrolÃ¼
   â”œâ”€> AkbankScraper instance oluÅŸtur
   â””â”€> AkbankScraper.scrape() Ã§aÄŸÄ±r

3. AkbankScraper
   â”œâ”€> Puppeteer browser aÃ§
   â”œâ”€> https://www.akbank.com/kampanyalar yÃ¼kle
   â”œâ”€> Sayfa yÃ¼klenmesini bekle
   â”œâ”€> DOM'dan kampanya elementlerini bul
   â”œâ”€> Raw data extract et
   â””â”€> BaseScraper.normalize() Ã§aÄŸÄ±r

4. Normalizer
   â”œâ”€> Raw data'yÄ± standart formata Ã§evir
   â”œâ”€> Hash oluÅŸtur (duplicate kontrolÃ¼ iÃ§in)
   â”œâ”€> Backend'de duplicate var mÄ± kontrol et
   â””â”€> Yeni ise APIClient'a gÃ¶nder

5. APIClient
   â”œâ”€> POST /api/campaigns
   â””â”€> Response'u log'la

6. ScraperManager
   â””â”€> Sonucu log'la (baÅŸarÄ±lÄ±/baÅŸarÄ±sÄ±z)
```

## ğŸ“Š Akbank Scraper TasarÄ±mÄ±

### Sayfa YapÄ±sÄ± (Tahmini)
```
https://www.akbank.com/kampanyalar
â”œâ”€â”€ Campaign List Container
â”‚   â”œâ”€â”€ Campaign Card 1
â”‚   â”‚   â”œâ”€â”€ Title
â”‚   â”‚   â”œâ”€â”€ Description
â”‚   â”‚   â”œâ”€â”€ Expiry Date
â”‚   â”‚   â””â”€â”€ Link
â”‚   â”œâ”€â”€ Campaign Card 2
â”‚   â””â”€â”€ ...
```

### Parse Stratejisi
```javascript
// Pseudo-code
async scrape() {
  await page.goto('https://www.akbank.com/kampanyalar');
  await page.waitForSelector('.campaign-list'); // veya benzeri
  
  const campaigns = await page.evaluate(() => {
    const cards = document.querySelectorAll('.campaign-card');
    return Array.from(cards).map(card => ({
      title: card.querySelector('.title')?.textContent,
      description: card.querySelector('.description')?.textContent,
      url: card.querySelector('a')?.href,
      expiry: card.querySelector('.expiry')?.textContent,
    }));
  });
  
  return campaigns;
}
```

### Normalize Stratejisi
```javascript
normalize(rawData) {
  return {
    sourceId: 'akbank-uuid', // Backend'den alÄ±nacak
    title: rawData.title,
    description: rawData.description,
    originalUrl: rawData.url,
    expiresAt: parseDate(rawData.expiry),
    // ... diÄŸer alanlar
  };
}
```

## ğŸ“Š Turkcell Scraper TasarÄ±mÄ±

### Sayfa YapÄ±sÄ± (Tahmini)
```
https://www.turkcell.com.tr/kampanyalar
â”œâ”€â”€ SPA (Single Page Application)
â”‚   â”œâ”€â”€ Dynamic content loading
â”‚   â”œâ”€â”€ Campaign Cards (lazy loaded)
â”‚   â””â”€â”€ Infinite scroll olabilir
```

### Parse Stratejisi
```javascript
// Pseudo-code
async scrape() {
  await page.goto('https://www.turkcell.com.tr/kampanyalar');
  
  // SPA iÃ§in ekstra bekleme
  await page.waitForTimeout(3000);
  await page.waitForSelector('.campaign-item'); // veya benzeri
  
  // Scroll yaparak tÃ¼m iÃ§eriÄŸi yÃ¼kle (gerekirse)
  await autoScroll(page);
  
  const campaigns = await page.evaluate(() => {
    // Similar to Akbank
  });
  
  return campaigns;
}
```

## ğŸ›¡ï¸ Error Handling Stratejisi

### Retry Logic
```javascript
async function retry(fn, maxRetries = 3) {
  for (let i = 0; i < maxRetries; i++) {
    try {
      return await fn();
    } catch (error) {
      if (i === maxRetries - 1) throw error;
      await sleep(calculateBackoff(i));
    }
  }
}
```

### Error Types
- **NetworkError**: Retry
- **TimeoutError**: Retry
- **ParseError**: Log + Skip (sayfa yapÄ±sÄ± deÄŸiÅŸmiÅŸ olabilir)
- **403Forbidden**: Log + Alert (anti-bot tetiklenmiÅŸ)
- **404NotFound**: Log + Alert (URL deÄŸiÅŸmiÅŸ)

## ğŸ“ Logging Stratejisi

### Log Levels
- **INFO**: Normal iÅŸlemler (scraping baÅŸladÄ±, tamamlandÄ±)
- **WARN**: Retry yapÄ±ldÄ±, geÃ§ici hata
- **ERROR**: KalÄ±cÄ± hata, manuel mÃ¼dahale gerekli
- **DEBUG**: DetaylÄ± bilgi (development iÃ§in)

### Log Format
```
[2026-01-16 10:30:15] [INFO] [AkbankScraper] Scraping started
[2026-01-16 10:30:20] [INFO] [AkbankScraper] Found 5 campaigns
[2026-01-16 10:30:25] [INFO] [AkbankScraper] 3 new campaigns posted to API
[2026-01-16 10:30:25] [INFO] [AkbankScraper] Scraping completed successfully
```

## ğŸ” Rate Limiting

### Strateji
- Her kaynak iÃ§in: 1 request / 30 saniye
- Paralel scraping: Max 2 kaynak aynÄ± anda
- Global limit: 10 request / dakika (tÃ¼m kaynaklar)

### Implementation (Pseudo)
```javascript
class RateLimiter {
  constructor(requestsPerMinute = 2) {
    this.queue = [];
    this.interval = 60000 / requestsPerMinute;
  }
  
  async wait() {
    // Queue-based rate limiting
  }
}
```

## ğŸ¯ Sonraki AdÄ±mlar (Implementation)

1. **BaseScraper Abstract Class**
   - Ortak metodlar (scrape, parse, normalize)
   - Puppeteer setup/teardown
   - Error handling

2. **AkbankScraper**
   - Sayfa yapÄ±sÄ±nÄ± analiz et
   - Selector'larÄ± belirle
   - Parse logic'i yaz
   - Test et

3. **TurkcellScraper**
   - Sayfa yapÄ±sÄ±nÄ± analiz et
   - SPA handling
   - Parse logic'i yaz
   - Test et

4. **ScraperManager**
   - Orchestration logic
   - Rate limiting
   - Error handling
   - Logging

5. **Scheduler**
   - Cron job setup
   - Configurable interval
   - Graceful shutdown

6. **Integration**
   - Backend API entegrasyonu
   - End-to-end test
   - Production deployment
